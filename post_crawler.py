import os
import sys
import time
import json
import re
from pathlib import Path
from typing import List, Dict, Union, Optional
from datetime import datetime
import calendar

# æ·»åŠ shuiyuan_exporteræ¨¡å—åˆ°è·¯å¾„
sys.path.append('./shuiyuan_exporter')
sys.path.append('./translationAPI')

from shuiyuan_exporter.main import export_exec
from shuiyuan_exporter.utils import read_cookie
import re
# å¯¼å…¥ç¿»è¯‘åŠŸèƒ½
try:
    from translationAPI.translator import translate_text, translate_batch
    TRANSLATION_AVAILABLE = True
    print("ğŸŒ ç¿»è¯‘åŠŸèƒ½å·²åŠ è½½")
except ImportError:
    TRANSLATION_AVAILABLE = False
    print("âš ï¸ ç¿»è¯‘åŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥translationAPI/translator.py")

# å¯¼å…¥è¡¨æƒ…ç¬¦å·è½¬æ¢åŠŸèƒ½
try:
    from translationAPI.emoji_converter import convert_discourse_emojis
    EMOJI_CONVERSION_AVAILABLE = True
    print("ğŸ˜Š è¡¨æƒ…ç¬¦å·è½¬æ¢åŠŸèƒ½å·²åŠ è½½")
except ImportError:
    EMOJI_CONVERSION_AVAILABLE = False
    print("âš ï¸ è¡¨æƒ…ç¬¦å·è½¬æ¢åŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥emoji_converter.py")


def clean_text_for_translation(text: str, convert_emojis: bool = True) -> str:
    """
    æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤æˆ–è½¬æ¢ä¸éœ€è¦ç¿»è¯‘çš„å†…å®¹
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        convert_emojis: æ˜¯å¦è½¬æ¢è¡¨æƒ…ç¬¦å·ï¼ˆTrue=è½¬æ¢ä¸ºUnicodeï¼ŒFalse=ç§»é™¤ï¼‰
        
    Returns:
        æ¸…ç†åçš„æ–‡æœ¬
    """
    if not text:
        return ""
    
    # å¤„ç†è¡¨æƒ…ç¬¦å·ï¼ˆ:emoji_name:æ ¼å¼ï¼‰
    if convert_emojis and EMOJI_CONVERSION_AVAILABLE:
        # è½¬æ¢ä¸ºUnicodeè¡¨æƒ…ç¬¦å·
        text = convert_discourse_emojis(text)
    else:
        # ç§»é™¤è¡¨æƒ…ç¬¦å·
        text = re.sub(r':[a-zA-Z0-9_+-]+:', '', text)
    
    # ç§»é™¤å›¾ç‰‡æ ‡è®°
    text = re.sub(r'!\[.*?\]\(.*?\)', '', text)
    
    # ç§»é™¤é“¾æ¥
    text = re.sub(r'\[.*?\]\(.*?\)', '', text)
    
    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text


def process_post_text(text: str, convert_emojis: bool = True) -> str:
    """
    å¤„ç†å¸–å­æ–‡æœ¬ï¼Œè½¬æ¢è¡¨æƒ…ç¬¦å·ä½†ä¿ç•™å…¶ä»–å†…å®¹
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        convert_emojis: æ˜¯å¦è½¬æ¢è¡¨æƒ…ç¬¦å·ä¸ºUnicode
        
    Returns:
        å¤„ç†åçš„æ–‡æœ¬
    """
    if not text:
        return ""
    
    # è½¬æ¢Discourseè¡¨æƒ…ç¬¦å·ä¸ºUnicodeè¡¨æƒ…ç¬¦å·
    if convert_emojis and EMOJI_CONVERSION_AVAILABLE:
        text = convert_discourse_emojis(text)
    
    return text


def parse_post_content(file_path: str, enable_translation: bool = False, batch_size: int = 10, convert_emojis: bool = True) -> List[Dict]:
    """
    è§£æå¸–å­markdownæ–‡ä»¶å†…å®¹ä¸ºç»“æ„åŒ–æ•°æ®
    
    å‚æ•°:
        file_path (str): å¸–å­æ–‡ä»¶è·¯å¾„
        enable_translation (bool): æ˜¯å¦å¯ç”¨ç¿»è¯‘åŠŸèƒ½
        batch_size (int): æ‰¹é‡ç¿»è¯‘çš„æ‰¹æ¬¡å¤§å°
        convert_emojis: æ˜¯å¦è½¬æ¢è¡¨æƒ…ç¬¦å·ä¸ºUnicode
        
    è¿”å›:
        List[Dict]: åŒ…å«æ‰€æœ‰å‘è¨€çš„åˆ—è¡¨
    """
    posts = []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
        
        # æŒ‰åˆ†éš”çº¿åˆ†å‰²å„ä¸ªå‘è¨€
        sections = content.split('-------------------------')
        
        total_posts = len([s for s in sections if s.strip()])
        print(f"ğŸ“„ å‡†å¤‡è§£æ {total_posts} æ¡å‘è¨€...")
        
        for i, section in enumerate(sections):
            section = section.strip()
            if not section:
                continue
                
            lines = section.split('\n')
            if len(lines) < 2:
                continue
            
            # è§£æç¬¬ä¸€è¡Œï¼šä½œè€… | æ—¶é—´ | #ç¼–å·
            header_line = lines[0].strip()
            header_match = re.match(r'^(.+?)\s*\|\s*(.+?)\s*\|\s*#(\d+)$', header_line)
            
            if not header_match:
                continue
                
            author = header_match.group(1).strip()
            timestamp_str = header_match.group(2).strip()
            current_post_id = header_match.group(3).strip()  # å½“å‰å‘è¨€çš„ID
            
            # è§£ææ—¶é—´
            try:
                # ç§»é™¤ "UTC" å¹¶è§£ææ—¶é—´
                timestamp_clean = timestamp_str.replace(' UTC', '')
                dt = datetime.strptime(timestamp_clean, '%Y-%m-%d %H:%M:%S')
                
                # æ ¼å¼åŒ–ä¸ºè¦æ±‚çš„æ ¼å¼ "2025-05-30 06:59:01"
                created_time = dt.strftime('%Y-%m-%d %H:%M:%S')
                
                # è½¬æ¢ä¸ºUTCæ—¶é—´æˆ³ï¼ˆæ•´æ•°ï¼‰
                created_utc = int(calendar.timegm(dt.timetuple()))
                
            except:
                created_time = timestamp_str
                created_utc = 0
            
            # æå–æ­£æ–‡å†…å®¹ï¼ˆé™¤ç¬¬ä¸€è¡Œå¤–çš„æ‰€æœ‰è¡Œï¼‰
            content_lines = lines[1:]
            text_content = '\n'.join(content_lines).strip()
            
            # å¤„ç†å¼•ç”¨ä¿¡æ¯
            quote_ids = []
            
            # æŸ¥æ‰¾æ‰€æœ‰å¼•ç”¨å¹¶æå–ä¿¡æ¯
            # åŒ¹é…æ ¼å¼ï¼š[quote="ç”¨æˆ·å, post:1, topic:377979, username:ç”¨æˆ·å"]å†…å®¹[/quote]
            quote_pattern = r'\[quote="[^"]*post:(\d+)[^"]*"\]\s*(.*?)\s*\[/quote\]'
            quotes = re.findall(quote_pattern, text_content, re.DOTALL)
            
            # æ”¶é›†å¼•ç”¨çš„å‘è¨€ID
            for post_id, quoted_text in quotes:
                quote_ids.append(int(post_id))
            
            # æ›¿æ¢textä¸­çš„quoteæ ‡ç­¾ï¼Œä¿ç•™å¼•ç”¨æ ‡è¯†ä½†ä½¿ç”¨ç®€æ´æ ¼å¼
            def replace_quote(match):
                quoted_text = match.group(2).strip()
                # ä½¿ç”¨ç®€æ´çš„ [quote] [/quote] æ ¼å¼
                return f"[quote]{quoted_text}[/quote]"
            
            text_content = re.sub(quote_pattern, replace_quote, text_content)
            
            # å¤„ç†è¡¨æƒ…ç¬¦å·è½¬æ¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if convert_emojis:
                text_content = process_post_text(text_content, convert_emojis)
            
            # å‡†å¤‡åŸºæœ¬æ•°æ®
            post_data = {
                "author": author,
                "created_time": created_time,  # ä¿®æ”¹å­—æ®µå
                "created_utc": created_utc,    # UTCæ—¶é—´æˆ³
                "body": text_content,          # ä¿®æ”¹å­—æ®µå
                "id": int(current_post_id),    # ä½¿ç”¨headerä¸­çš„å‘è¨€ID
                "quote": quote_ids if quote_ids else None
            }
            
            posts.append(post_data)
    
        # æ‰¹é‡ç¿»è¯‘å¤„ç†
        if enable_translation and TRANSLATION_AVAILABLE and posts:
            print(f"ğŸŒ å¼€å§‹æ‰¹é‡ç¿»è¯‘ {len(posts)} æ¡å‘è¨€...")
            
            # å‡†å¤‡å¾…ç¿»è¯‘çš„æ–‡æœ¬
            texts_to_translate = []
            for post in posts:
                clean_text = clean_text_for_translation(post["body"], convert_emojis)
                texts_to_translate.append(clean_text if clean_text else None)
            
            # åˆ†æ‰¹å¤„ç†ç¿»è¯‘
            batch_count = 0
            total_batches = (len(texts_to_translate) + batch_size - 1) // batch_size
            
            for i in range(0, len(texts_to_translate), batch_size):
                batch_count += 1
                batch_texts = texts_to_translate[i:i + batch_size]
                batch_posts = posts[i:i + batch_size]
                
                print(f"ğŸ”„ æ­£åœ¨ç¿»è¯‘æ‰¹æ¬¡ {batch_count}/{total_batches} ({len(batch_texts)} æ¡å‘è¨€)...")
                
                try:
                    # æ‰¹é‡ç¿»è¯‘
                    translated_results = translate_batch(batch_texts, from_lang='zh', to_lang='en')
                    
                    # å°†ç¿»è¯‘ç»“æœåˆ†é…ç»™å¯¹åº”çš„å‘è¨€
                    for j, translated_text in enumerate(translated_results):
                        post_index = i + j
                        if post_index < len(posts):
                            posts[post_index]["body_en"] = translated_text
                    
                    success_count = sum(1 for result in translated_results if result is not None)
                    print(f"âœ… æ‰¹æ¬¡ {batch_count} å®Œæˆ: {success_count}/{len(batch_texts)} æ¡ç¿»è¯‘æˆåŠŸ")
                    
                except Exception as e:
                    print(f"âŒ æ‰¹æ¬¡ {batch_count} ç¿»è¯‘å¤±è´¥: {e}")
                    # ä¸ºå½“å‰æ‰¹æ¬¡çš„å‘è¨€è®¾ç½®ç¿»è¯‘ä¸ºNone
                    for j in range(len(batch_texts)):
                        post_index = i + j
                        if post_index < len(posts):
                            posts[post_index]["body_en"] = None
                
                # æ‰¹æ¬¡é—´å»¶è¿Ÿ
                if batch_count < total_batches:
                    time.sleep(1.0)  # æ‰¹æ¬¡é—´å»¶è¿Ÿ1ç§’
            
            # ç»Ÿè®¡ç¿»è¯‘ç»“æœ
            total_translated = sum(1 for post in posts if post.get("body_en") is not None)
            print(f"ğŸŒ æ‰¹é‡ç¿»è¯‘å®Œæˆ: {total_translated}/{len(posts)} æ¡å‘è¨€ç¿»è¯‘æˆåŠŸ")
        
        else:
            # å¦‚æœä¸å¯ç”¨ç¿»è¯‘ï¼Œä¸ºæ‰€æœ‰å‘è¨€æ·»åŠ ç©ºçš„body_enå­—æ®µ
            if enable_translation:
                for post in posts:
                    post["body_en"] = None
    
    except Exception as e:
        print(f"è§£ææ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return []
    
    return posts


def shuiyuan_crawler(post_id: str, to_json: bool = False, enable_translation: bool = False, batch_size: int = 10, convert_emojis: bool = True) -> Union[bool, List[Dict]]:
    """
    çˆ¬å–å•ä¸ªå¸–å­å¹¶å¯é€‰åœ°è¿”å›JSONæ ¼å¼æ•°æ®
    
    å‚æ•°:
        post_id (str): å¸–å­ç¼–å·
        to_json (bool): æ˜¯å¦è¿”å›JSONæ ¼å¼æ•°æ®ï¼Œé»˜è®¤ä¸ºFalse
        enable_translation (bool): æ˜¯å¦å¯ç”¨ç¿»è¯‘åŠŸèƒ½
        batch_size (int): æ‰¹é‡ç¿»è¯‘çš„æ‰¹æ¬¡å¤§å°
        convert_emojis: æ˜¯å¦è½¬æ¢è¡¨æƒ…ç¬¦å·ä¸ºUnicode
        
    è¿”å›:
        Union[bool, List[Dict]]: 
        - å½“to_json=Falseæ—¶ï¼Œè¿”å›boolè¡¨ç¤ºæ˜¯å¦æˆåŠŸ
        - å½“to_json=Trueæ—¶ï¼Œè¿”å›åŒ…å«æ‰€æœ‰å‘è¨€çš„åˆ—è¡¨
    """
    try:
        # ç¡®ä¿post_idæ˜¯å­—ç¬¦ä¸²æ ¼å¼
        post_id = str(post_id)
        
        # ç§»é™¤å¯èƒ½çš„Lå‰ç¼€ï¼ˆå…¼å®¹è€APIï¼‰
        if post_id.startswith("L"):
            post_id = post_id[1:]
            
        print(f'å¼€å§‹çˆ¬å–å¸–å­ #{post_id}...')
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„cookie
        cookie_string = read_cookie()
        if not cookie_string:
            print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°ç¼“å­˜çš„cookieï¼Œè¯·å…ˆè®¾ç½®cookie")
            print("ğŸ’¡ è§£å†³æ–¹æ³•ï¼šè¿è¡Œ cd shuiyuan_exporter && python main.py æ¥è®¾ç½®cookie")
            return False if not to_json else []
        
        print(f"âœ… Cookieå·²åŠ è½½ï¼Œé•¿åº¦: {len(cookie_string)} å­—ç¬¦")
            
        # è®¾ç½®ä¿å­˜è·¯å¾„ - æ³¨æ„ï¼šexport_execä¼šè‡ªåŠ¨åˆ›å»ºä»¥post_idå‘½åçš„å­ç›®å½•
        save_dir = "./Cache/Posts"  # ä¸åŒ…å«post_idï¼Œé¿å…åµŒå¥—
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        
        # å®é™…çš„å¸–å­ç›®å½•ï¼ˆexport_execä¼šåˆ›å»ºè¿™ä¸ªï¼‰
        actual_post_dir = f"{save_dir}/{post_id}"
        print(f"ğŸ“ ä¿å­˜ç›®å½•: {actual_post_dir}")
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # è°ƒç”¨ä¸»è¦çš„å¯¼å‡ºé€»è¾‘
        try:
            export_exec(topic=post_id, save_dir=save_dir)  # ä¼ å…¥åŸºç¡€ç›®å½•ï¼Œä¸åŒ…å«post_id
        except Exception as export_error:
            print(f"âŒ çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {export_error}")
            
            # æä¾›å…·ä½“çš„é”™è¯¯è¯Šæ–­
            error_str = str(export_error)
            if "'posts_count'" in error_str:
                print("ğŸ” è¯Šæ–­ï¼šæ— æ³•è·å–å¸–å­ä¿¡æ¯")
                print("   å¯èƒ½åŸå› ï¼š")
                print("   1. å¸–å­IDä¸å­˜åœ¨æˆ–æ— æ•ˆ")
                print("   2. Cookieå·²è¿‡æœŸï¼Œéœ€è¦é‡æ–°è®¾ç½®")
                print("   3. å¸–å­éœ€è¦ç‰¹æ®Šæƒé™è®¿é—®")
                print("   4. ç½‘ç»œè¿æ¥é—®é¢˜")
                print(f"ğŸ’¡ å»ºè®®ï¼šå°è¯•ä½¿ç”¨ä¸€ä¸ªå·²çŸ¥å­˜åœ¨çš„å¸–å­IDï¼Œå¦‚ï¼š377979")
            elif "ç½‘ç»œ" in error_str or "è¿æ¥" in error_str:
                print("ğŸ” è¯Šæ–­ï¼šç½‘ç»œè¿æ¥é—®é¢˜")
                print("ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥å’Œä»£ç†è®¾ç½®")
            elif "æƒé™" in error_str or "403" in error_str:
                print("ğŸ” è¯Šæ–­ï¼šæƒé™ä¸è¶³")
                print("ğŸ’¡ å»ºè®®ï¼šé‡æ–°è®¾ç½®cookieæˆ–æ£€æŸ¥è´¦å·æƒé™")
            
            return False if not to_json else []
        
        # è®¡ç®—æ€»è€—æ—¶
        total_time = time.time() - start_time
        print(f"â±ï¸ å¸–å­ #{post_id} çˆ¬å–å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f} ç§’")
        print(f"ğŸ“‚ æ–‡ä»¶ä¿å­˜åœ¨: {actual_post_dir}")
        
        # å¦‚æœéœ€è¦JSONæ ¼å¼ï¼Œè§£ææ–‡ä»¶å†…å®¹
        if to_json:
            # æŸ¥æ‰¾ç”Ÿæˆçš„markdownæ–‡ä»¶
            md_files = list(Path(actual_post_dir).glob(f"{post_id}*.md"))
            if md_files:
                md_file = md_files[0]
                print(f"ğŸ“„ è§£ææ–‡ä»¶: {md_file}")
                posts_data = parse_post_content(str(md_file), enable_translation, batch_size, convert_emojis)
                
                if not posts_data:
                    print("âš ï¸ è­¦å‘Šï¼šè§£æåˆ°0æ¡å‘è¨€ï¼Œå¯èƒ½markdownæ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®")
                    # æ£€æŸ¥æ–‡ä»¶å†…å®¹
                    try:
                        with open(md_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        if len(content.strip()) == 0:
                            print("ğŸ” è¯Šæ–­ï¼šmarkdownæ–‡ä»¶ä¸ºç©º")
                        else:
                            print(f"ğŸ” æ–‡ä»¶å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                            print(f"ğŸ” æ–‡ä»¶å‰100å­—ç¬¦: {content[:100]}...")
                    except Exception as e:
                        print(f"ğŸ” æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹: {e}")
                
                # ä¿å­˜JSONæ–‡ä»¶
                json_file = md_file.with_suffix('.json')
                with open(json_file, 'w', encoding='utf-8') as f:
                    json.dump(posts_data, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ JSONæ•°æ®å·²ä¿å­˜åˆ°: {json_file}")
                
                return posts_data
            else:
                print("âŒ æœªæ‰¾åˆ°ç”Ÿæˆçš„markdownæ–‡ä»¶")
                print("ğŸ” è¯Šæ–­ï¼šçˆ¬å–å¯èƒ½å¤±è´¥ï¼Œæ²¡æœ‰ç”Ÿæˆå†…å®¹æ–‡ä»¶")
                return []
        
        return True
        
    except Exception as e:
        print(f"âŒ çˆ¬å–å¸–å­ #{post_id} æ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")
        print(f"ğŸ” é”™è¯¯ç±»å‹: {type(e).__name__}")
        return False if not to_json else []


def crawl_single_post(post_id: str) -> bool:
    """
    çˆ¬å–å•ä¸ªå¸–å­å¹¶ä¿å­˜åˆ°ç¼“å­˜ç›®å½•ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    
    å‚æ•°:
        post_id (str): å¸–å­ç¼–å·
        
    è¿”å›:
        bool: çˆ¬å–æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
    """
    result = shuiyuan_crawler(post_id, to_json=False, enable_translation=False)
    return isinstance(result, bool) and result


def crawl_multiple_posts(post_ids: list, to_json: bool = False, enable_translation: bool = False, batch_size: int = 10, convert_emojis: bool = True) -> dict:
    """
    æ‰¹é‡çˆ¬å–å¤šä¸ªå¸–å­
    
    å‚æ•°:
        post_ids (list): å¸–å­ç¼–å·åˆ—è¡¨
        to_json (bool): æ˜¯å¦åŒæ—¶ç”ŸæˆJSONæ ¼å¼æ•°æ®
        enable_translation (bool): æ˜¯å¦å¯ç”¨ç¿»è¯‘åŠŸèƒ½
        batch_size (int): æ‰¹é‡ç¿»è¯‘çš„æ‰¹æ¬¡å¤§å°
        convert_emojis: æ˜¯å¦è½¬æ¢è¡¨æƒ…ç¬¦å·ä¸ºUnicode
        
    è¿”å›:
        dict: åŒ…å«æˆåŠŸå’Œå¤±è´¥å¸–å­çš„å­—å…¸
    """
    results = {
        'success': [],
        'failed': [],
        'data': {} if to_json else None
    }
    
    print(f"å¼€å§‹æ‰¹é‡çˆ¬å– {len(post_ids)} ä¸ªå¸–å­...")
    if enable_translation:
        print("ğŸŒ ç¿»è¯‘åŠŸèƒ½å·²å¯ç”¨")
    
    for post_id in post_ids:
        print(f"\n{'='*50}")
        result = shuiyuan_crawler(post_id, to_json=to_json, enable_translation=enable_translation, batch_size=batch_size, convert_emojis=convert_emojis)
        
        if to_json:
            if isinstance(result, list) and len(result) > 0:
                results['success'].append(post_id)
                results['data'][post_id] = result
            else:
                results['failed'].append(post_id)
        else:
            if result:
                results['success'].append(post_id)
            else:
                results['failed'].append(post_id)
    
    print(f"\n{'='*50}")
    print(f"æ‰¹é‡çˆ¬å–å®Œæˆï¼")
    print(f"æˆåŠŸ: {len(results['success'])} ä¸ª")
    print(f"å¤±è´¥: {len(results['failed'])} ä¸ª")
    
    if results['failed']:
        print(f"å¤±è´¥çš„å¸–å­: {results['failed']}")
    
    return results


if __name__ == "__main__":
    # ========== é…ç½®å˜é‡ ==========
    # åœ¨è¿™é‡Œè®¾ç½®è¦çˆ¬å–çš„å¸–å­å’Œé€‰é¡¹
    
    # å•ä¸ªå¸–å­çˆ¬å–ç¤ºä¾‹
    single_post_id = "377979"  # è®¾ç½®è¦çˆ¬å–çš„å•ä¸ªå¸–å­ID
    # æ¨èçš„æµ‹è¯•å¸–å­IDï¼ˆè¿™äº›æ˜¯å·²çŸ¥å­˜åœ¨çš„ï¼‰:
    # "377979" - ç«é”…å¸–å­ï¼ˆå·²éªŒè¯å­˜åœ¨ï¼‰
    # "123456" - è¯·æ›¿æ¢ä¸ºå®é™…å­˜åœ¨çš„å¸–å­ID
    # "789012" - è¯·æ›¿æ¢ä¸ºå®é™…å­˜åœ¨çš„å¸–å­ID
    
    enable_json = True         # æ˜¯å¦ç”ŸæˆJSONæ ¼å¼æ•°æ®
    enable_translation = True  # æ˜¯å¦å¯ç”¨ç¿»è¯‘åŠŸèƒ½ï¼ˆæ–°å¢ï¼‰
    batch_size = 10           # æ‰¹é‡ç¿»è¯‘çš„æ‰¹æ¬¡å¤§å°ï¼ˆæ–°å¢ï¼‰
    convert_emojis = True     # æ˜¯å¦è½¬æ¢è¡¨æƒ…ç¬¦å·ä¸ºUnicodeï¼ˆæ–°å¢ï¼‰
    
    # æ‰¹é‡å¸–å­çˆ¬å–ç¤ºä¾‹ï¼ˆå¦‚æœè¦æ‰¹é‡çˆ¬å–ï¼Œè¯·å–æ¶ˆæ³¨é‡Šå¹¶è®¾ç½®post_idsï¼‰
    # post_ids = ["377979", "123456", "789012"]  # è®¾ç½®è¦æ‰¹é‡çˆ¬å–çš„å¸–å­IDåˆ—è¡¨
    post_ids = None  # è®¾ç½®ä¸ºNoneè¡¨ç¤ºä¸è¿›è¡Œæ‰¹é‡çˆ¬å–
    
    # æ˜¯å¦å¯ç”¨äº¤äº’å¼æ¨¡å¼ï¼ˆå¦‚æœä¸ºTrueï¼Œä¼šæç¤ºç”¨æˆ·è¾“å…¥ï¼‰
    interactive_mode = False
    
    # ========== æ‰§è¡Œé€»è¾‘ ==========
    
    if interactive_mode:
        # äº¤äº’å¼è¾“å…¥æ¨¡å¼
        print("=== äº¤äº’å¼çˆ¬å–æ¨¡å¼ ===")
        while True:
            user_input = input("\nè¯·è¾“å…¥å¸–å­ç¼–å· (è¾“å…¥ 'quit' é€€å‡º, æ·»åŠ  '--json' ç”ŸæˆJSON, æ·»åŠ  '--translate' å¯ç”¨ç¿»è¯‘): ").strip()
            if user_input.lower() == 'quit':
                break
            
            parts = user_input.split()
            if not parts:
                continue
                
            post_id = parts[0]
            to_json = '--json' in parts
            translate = '--translate' in parts
            
            if post_id:
                result = shuiyuan_crawler(post_id, to_json=to_json, enable_translation=translate, batch_size=batch_size, convert_emojis=convert_emojis)
                if to_json and isinstance(result, list):
                    print(f"\nè§£æåˆ° {len(result)} æ¡å‘è¨€")
    
    elif post_ids is not None:
        # æ‰¹é‡çˆ¬å–æ¨¡å¼
        print("=== æ‰¹é‡çˆ¬å–æ¨¡å¼ ===")
        print(f"å°†è¦çˆ¬å–çš„å¸–å­: {post_ids}")
        print(f"JSONæ¨¡å¼: {'å¼€å¯' if enable_json else 'å…³é—­'}")
        print(f"ç¿»è¯‘æ¨¡å¼: {'å¼€å¯' if enable_translation else 'å…³é—­'}")
        print(f"è¡¨æƒ…ç¬¦å·è½¬æ¢: {'å¼€å¯' if convert_emojis else 'å…³é—­'}")
        print(f"æ‰¹æ¬¡å¤§å°: {batch_size} æ¡å‘è¨€/æ‰¹æ¬¡")
        
        results = crawl_multiple_posts(post_ids, to_json=enable_json, enable_translation=enable_translation, batch_size=batch_size, convert_emojis=convert_emojis)
        
        print(f"\næ‰¹é‡çˆ¬å–å®Œæˆï¼")
        print(f"æˆåŠŸ: {len(results['success'])} ä¸ª")
        print(f"å¤±è´¥: {len(results['failed'])} ä¸ª")
        
        if enable_json and results['data']:
            total_posts = sum(len(posts) for posts in results['data'].values())
            print(f"æ€»å…±è§£æäº† {total_posts} æ¡å‘è¨€")
    
    else:
        # å•ä¸ªå¸–å­çˆ¬å–æ¨¡å¼
        print("=== å•ä¸ªå¸–å­çˆ¬å–æ¨¡å¼ ===")
        print(f"çˆ¬å–å¸–å­: {single_post_id}")
        print(f"JSONæ¨¡å¼: {'å¼€å¯' if enable_json else 'å…³é—­'}")
        print(f"ç¿»è¯‘æ¨¡å¼: {'å¼€å¯' if enable_translation else 'å…³é—­'}")
        print(f"è¡¨æƒ…ç¬¦å·è½¬æ¢: {'å¼€å¯' if convert_emojis else 'å…³é—­'}")
        if enable_translation:
            print(f"æ‰¹æ¬¡å¤§å°: {batch_size} æ¡å‘è¨€/æ‰¹æ¬¡")
        
        result = shuiyuan_crawler(single_post_id, to_json=enable_json, enable_translation=enable_translation, batch_size=batch_size, convert_emojis=convert_emojis)
        
        if enable_json and isinstance(result, list):
            print(f"\nâœ… çˆ¬å–æˆåŠŸï¼è§£æåˆ° {len(result)} æ¡å‘è¨€")
            if enable_translation:
                translated_count = sum(1 for post in result if post.get('body_en') is not None)
                print(f"ğŸŒ æˆåŠŸç¿»è¯‘ {translated_count} æ¡å‘è¨€")
        elif not enable_json and result:
            print(f"\nâœ… çˆ¬å–æˆåŠŸï¼")
        else:
            print(f"\nâŒ çˆ¬å–å¤±è´¥")
    
    print("\nç¨‹åºæ‰§è¡Œå®Œæˆã€‚") 